LinRegModel4 = lm(ElantraSales ~ MonthFactor + Unemployment + CPI_energy + CPI_all , data=train)
LinRegModel4Pred = predict(LinRegModel4 , newdata=test)
test$MonthFactor = as.factor(test$Month)
LinRegModel4Pred = predict(LinRegModel4 , newdata=test)
max(abs(test$ElantraSales-LinRegModel4Pred))
which.max(abs(test$ElantraSales-LinRegModel4Pred))
test$MonthFactor[14]
which.max(abs(LinRegModel4Pred))
test$MonthFactor[30]
test$MonthFactor[9]
max(LinRegModel4Pred)
which.max(LinRegModel4Pred)
which.max(test$ElantraSales-LinRegModel4Pred)
test$MonthFactor[14]
test$Month[14]
test$Year[14]
test$Month[5]
which.max(test$ElantraSales-LinRegModel4Pred)
test$Year[5]
which.max(abs(test$ElantraSales-LinRegModel4Pred))
test$Month[14]
test$Year[14]
test$Month[5]
news = read.csv("nytimes.csv")
str(news)
news = read.csv("nytimes.csv", stringsAsFactors=FALSE)
str(news)
summary(news)
table(news$popular)
105/nrow(news)
prop.table(news$popular)
prop.table(table(news$popular)
prop.table(table(news$popular))
prop.table(table(news$popular))
cor(news$word.count, news$popular)
cor(news)
cor(news$popular, news$word.count)
str(news$headline)
cor(news$popular, length(news$headline)
cor(news$popular, length(news$headline))
cor(news$popular, length(news$headline))
for(i in 1:973){
news$headline.word.count[i] <- length(news$headline[i])
}
news$headline.word.count
for(i in 1:973){
news$headline.word.count[i] <- nchar(news$headline[i])
}
news$headline.word.count
cor(news$popular, news$headline.word.count))
cor(news$popular, news$headline.word.count)
class(news$headline)
install.packages("stringr")
library(stringr)
test = as.character(c("My name is Fahad", "Her name is Annum"))
test
class(test)
news$headline
test = as.character(c("My name is Fahad", "Her name is Annum", "Rish is my sis"))
test
word(test,start=1L, end=start)
word(test,start=1L)
word(test,start=1L, sep=fixed(" "))
word(news$headline)
news$headline
cor(news$popular, news$headline.word.count)
news$popular = as.factor(news$popular)
news$type = as.factor(news$type)
str(news)
library(caTools)
set.seed(144)
spl = sample.split(news$popular, SplitRatio=0.7)
train = subset(news,spl==TRUE)
test = subset(news,spl == FALSE)
LogModel = glm(popular ~ print + type + word.count, data=train, family=binomial)
summary(LogModel)
str(train$type)
train$type
-0.8468333 * 1 + 0.9055929*2 + 682*0.0002600
682*0.0002600
0.9055929*2
-0.8468333 * 1 + 0.9055929*1 + 682*0.0002600
summary(LogModel)
-0.8468333 * 1 + 0.9055929*2 + 682*0.0002600
-2.5075573 -0.8468333 * 1 + 0.9055929*1 + 682*0.0002600
exp(-2.271478)/(1 + exp(-2.271478))
LogRegPred = predict(LogModel, newdata=test, type="response")
table(test$popular, LogRegPred >= 0.5)
LogRegPred
table(test$popular, LogRegPred >= 0.5)
table(test$popular)
260/nrow(test)
summary(LogRegPred)
library(ROCR)
pred = prediction(LogRegPred, test$popular)
as.numeric(performance(pred, "auc")@y.values)
library(ROCR)
ROCRperf = performance(pred, "tpr", "fpr")
plot(ROCRperf)
plot(ROCRperf,colorize=TRUE)
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.01), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.2), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.15), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.5), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.09), text.adj=c(-0.2,1.7))
set.seed(144)
library(caret)
library(e1071)
tree.control = trainControl(method="cv", number=10)
50 * 0.01
cp.grid = expand.grid(.cp = seq(0.01, 0.5, 0.01) )
tr= train(popular ~ print + type + word.count , data=train, method="rpart", trControl=tree.control, tuneGrid=cp.grid)
library(rpart)
tr= train(popular ~ print + type + word.count , data=train, method="rpart", trControl=tree.control, tuneGrid=cp.grid)
tr
popular.Tree.CP = rpart(popular ~ . , data=train, control=rpart.control(cp=0.01))
popular.Tree.CP = rpart(popular ~ . ,method="class", data=train, control=rpart.control(cp=0.01))
prp(popular.Tree.CP)
library(rpart)
library(rpart.plot)
popular.Tree.CP = rpart(popular ~ . ,method="class", data=train, control=rpart.control(cp=0.01))
prp(popular.Tree.CP)
popular.Tree.CP = rpart(popular ~ print + type + word.count ,method="class", data=train, control=rpart.control(cp=0.01))
prp(popular.Tree.CP)
library(tm)
corpusTitle = Corpus(VectorSource(news$snippet))
corpus = Corpus(VectorSource(news$snippet))
rm(corpusTitle)
corpusAdded
corpus
corpus[[1]]
corpus[[2]]
corpus[[3]]
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus[[1]]
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
articleText = as.data.frame(as.matrix(spdtm))
str(articleText)
sort(colSums(articleText))
summary(articleText)
articleText$print = news$print
articleText$type = news$type
articleText$word.count = news$word.count
articleText$popular = news$popular
str(articleText)
trainText = subset(articleText, spl==TRUE)
testText = subset(articleText, spl==FALSE)
glmText = glm(popular ~ . , data=trainText, family=binomial)
summary(LogModel)
trainText
summary(glmText)
LogRegPred2 = predict(glmText, newdata=testText, type="response")
pred2 = prediction(LogRegPred2, testText$popular)
as.numeric(performance(pred2, "auc")@y.values)
as.numeric(performance(pred, "auc")@y.values)
table(testText$popular, LogRegPred2 >= 0.5)
summary(LogRegPred2)
stocks = read.csv("nasdaq_returns.csv")
str(stocks)
summary(stocks)
table(stocks$stock_symbol)
head(stocks)
sum(table(stocks$stock_symbol))
table(stocks$industry)
str(stocks)
stocks$ret2000.12
sort(stocks$ret2000.12)
1153-850
tapply(stocks$ret2000.12,stocks$stock_symbol, sum)
sort(tapply(stocks$ret2000.12,stocks$stock_symbol, sum))
sum(table(stocks$ret2000.10))
sum(table(stocks$stock_symbol))
sum(table(stocks$stock_symbol, stocks$ret2000.10))
table(stocks$stock_symbol, stocks$ret2000.10))
table(stocks$stock_symbol, stocks$ret2000.10)
str(stocks)
sort(tapply(stocks$ret2000.12,stocks$stock_symbol, sum))
sort(table(tapply(stocks$ret2000.12,stocks$stock_symbol, sum)))
sort(stocks$ret2000.12>0.10)
sum(sort(stocks$ret2000.12>0.10))
sum(sort(stocks$ret2000.12>=0.10))
sum(sort(stocks$ret2000.12<=-0.10))
table(stocks$industry, stocks$ret2008.10)
sort(table(stocks$industry, stocks$ret2008.10))
stocks$ret2008.10
tapply(stocks$ret2008.10,stocks$industry,sum)
sort(tapply(stocks$ret2008.10,stocks$industry,sum))
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2000.02,stocks$industry,sum))
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,mean))
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,sum))
tapply(stocks$ret2008.10,stocks$industry,mean)
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,mean))
limited = stocks
limited$stock_symbol = NULL
limited$industry = NULL
limited$subindustry = NULL
str(limited)
which.max(mean(limited))
mean(limited)
col_names = colnames(limited)
col_names
res = data.frame()
for(i in col_names){
res$col_name = i
res$mean = mean(limited[i])
}
limited[ret2000.01]
limited$ret2000.01
head(limited)
head(limited[,1])
res = data.frame(ID=limited[,1], Means=rowMeans(limited[,-1]))
str(res)
sort(res$Means)
rm(res)
rm(col_names)
rm(i)
sor(colMeans(limited)
sor(colMeans(limited))
sor(colMeans(limited))
sort(colMeans(limited))
which.max(colMeans(limited))
which.min(colMeans(limited))
setwd("~/R Projects/Data")
dailyKOS = read.csv("dailykos.csv")
str(dailyKOS)
class(dailyKOS)
limitedMatrix = as.matrix(limited)
str(limitedMatrix)
limitedVector = as.vector(limitedMatrix)
str(limitedVector)
dailyKOSMatrix = as.matrix(dailyKOS)
str(dailyKOSMatrix)
dailyKOSVector = as.vector(dailyKOSMatrix)
str(dailyKOSVector)
dailyKOS = read.csv("dailykos.csv")
dailyKOSMatrix = as.matrix(dailyKOS)
dailyKOSVector = as.vector(dailyKOSMatrix)
str(dailyKOSVector)
str(dailyKOSMatrix)
3430*1546
str(dailyKOSVector)
distance = dist(limited, method="euclidean")
LimitedClusters = hclust(distance, method="ward")
LimitedClusters
plot(LimitedClusters)
rm(dailyKOS)
rm(dailyKOSMatrix)
rm(dailyKOSVector)
cluster5 = cutree(LimitedClusters, k=5)
table(cluster5)
sort(table(cluster5))
cluster1 = subset(limited, cluster5 == 1)
cluster2 = subset(limited, cluster5 == 2)
cluster3 = subset(limited, cluster5 == 3)
cluster4 = subset(limited, cluster5 == 4)
cluster5 = subset(limited, cluster5 == 5)
cluster1 = subset(stocks, cluster5 == 1)
cluster2 = subset(stocks, cluster5 == 2)
cluster3 = subset(stocks, cluster5 == 3)
cluster4 = subset(stocks, cluster5 == 4)
cluster5 = subset(stocks, cluster5 == 5)
cluster3
table(cluster5)
table(cluster5)
sort(table(cluster5))
cluster5 = cutree(LimitedClusters, k=5)
rm(cluster1)
rm(cluster2)
rm(cluster3)
rm(cluster4)
rm(cluster5)
cluster5 = cutree(LimitedClusters, k=5)
sort(table(cluster5))
cluster5
STR(cluster5)
str(cluster5)
mvt = read.csv("mvtWeek1.csv")
str(mvt)
max(mvt$ID)
min(mvt$Beat)
summary(mvt)
class(mvt$Date)
summary(mvt$Date)
DateConvert = as.Date(strptime(mvt$Date, "%m/%d/%y %H:%M"))
DateConvert
summary(DateConvert)
mvt$Month = months(DateConvert)
mvt$Weekday = weekdays(DateConvert)
mvt$Weekday
mvt$Month
mvt$Date = DateConvert
table(mvt$Month, mvt$LocationDescription)
table(mvt$Month)
sort(table(mvt$Month))
mvt$Weekday
table(mvt$Weekday)
sort(table(mvt$Weekday))
table(mvt$Arrest,mvt$Month)
sort(table(mvt$Arrest,mvt$Month))
table(mvt$Arrest,mvt$Month)
hist(mvt$Date, breaks=100)
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
data <- x$get()
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
setwd("~/R Projects/Coursera/Getting-and-Cleaning-Data/Data")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="Quiz3_Q1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf", destfile="code_book_Q1.pdf")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf", destfile="code_book_Q1.pdf")
housing = read.csv("Quiz3_Q1.csv")
str(housing)
agricultureLogical = housing[ACR==3 & AGS==6]
agricultureLogical = housing[c(ACR==3 & AGS==6)]
agricultureLogical = housing[housing$ACR==3 & housing$AGS==6]
agricultureLogical = housing$ACR==3 & housing$AGS==6
agricultureLogical
which(agricultureLogical)
install.packages("jpeg")
library(jpeg)
img = readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg",destfile="2Fjeff.jpg", mode="wb")
img <- readJPEG(system.file("img", "2Fjeff.jpg", package="jpeg"), TRUE)
library(jpeg)
img <- readJPEG("2Fjeff.jpg", native= TRUE)
quantile(img, probs=c(.3,.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="GDP_Data_Q3.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="educational_Data_Q3.csv")
gdp = read.csv("GDP_Data_Q3.csv")
education = read.csv("educational_Data_Q3.csv")
str(gdp)
str(education)
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=TRUE)
str(mergedData)
mergedData = merge(education, gdp, by.x="CountryCode", by.y="X", all=TRUE)
str(mergedData)
mergedData = merge(education, gdp, by.x="CountryCode", by.y="X", all=FALSE)
mergedData = merge(education, gdp, by.x="CountryCode", by.y="X", all=TRUE)
table(gdp$X)
table(gdp$X.2)
summary(gdp$X.2)
summary(gdp)
summary(education)
table(gdp$Gross.domestic.product.2012)
gdp$Gross.domestic.product.2012
gdp = read.csv("GDP_Data_Q3.csv",colClasses="character")
str(gdp)
education = read.csv("educational_Data_Q3.csv",colClasses="character")
str(education)
summary(gdp)
summary(education)
table(gdp$Gross.domestic.product.2012)
gdpNew = !(is.na(gdp$X) & is.na(gdp$Gross.domestic.product.2012))
gdpNew
gdpNew = gdp[!(is.na(gdp$X) & is.na(gdp$Gross.domestic.product.2012))]
gdp$X
gdp = subset(gdp, gdp$X != "")
gdp$X
gdp = read.csv("GDP_Data_Q3.csv",colClasses="character")
gdp = subset(gdp, gdp$X != "")
gdp$Gross.domestic.product.2012
gdp = subset(gdp, gdp$X != "" & gdp$Gross.domestic.product.2012 != "")
gdp$X
mergedData = merge(education, gdp, by.x="CountryCode", by.y="X", all=TRUE)
gdp$X
gdp$Gross.domestic.product.2012
gdp$X.1
gdp$X.2
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=TRUE)
str(mergedData)
gdp$Gross.domestic.product.2012
gdp$X != ""
gdp = subset(gdp, gdp$X != "" | gdp$Gross.domestic.product.2012 != "")
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=TRUE)
gdp$X
gdp$Gross.domestic.product.2012
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=TRUE)
str(mergedData)
mergedData$Gross.domestic.product.2012
sum(is.na(mergedData$Gross.domestic.product.2012))
229-45
education$CountryCode
gdp$X
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=FALSE)
str(mergedData)
sum(is.na(mergedData$Gross.domestic.product.2012))
mergedData$Long.Name
mergedData = order(mergedData$Gross.domestic.product.2012)
head(mergedData)
mergedData
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=FALSE)
order(mergedData$Gross.domestic.product.2012)
sort(mergedData$Gross.domestic.product.2012)
sort(as.numeric(mergedData$Gross.domestic.product.2012))
mergedData[sort(as.numeric(mergedData$Gross.domestic.product.2012))]
sort(as.numeric(mergedData$Gross.domestic.product.2012))
mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012))]
mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012)))]
mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012))]
mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012)),]
which(mergedData$Gross.domestic.product.2012==13)
mergedData$Long.Name[13]
mergedData <- mergedData[order(mergedData$Gross.domestic.product.2012) , ]
head(mergedData)
mergedData$Gross.domestic.product.2012
mergedData <- mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012)) , ]
mergedData$Gross.domestic.product.2012
mergedData$
mergedData$Long.Name
mergedData$Long.Name
mergedData$Gross.domestic.product.2012
mergedData$Long.Name
mergedData$Income.Group
sub_High_Income = subset(mergedData, mergedData$Income.Group == "High income: OECD" )
mean(sub_High_Income$Gross.domestic.product.2012)
mean(sub_High_Income$Gross.domestic.product.2012, na.rm=T)
mean(as.numeric(sub_High_Income$Gross.domestic.product.2012))
sub_High_Income_non = subset(mergedData, mergedData$Income.Group == "High income: nonOECD" )
mean(as.numeric(sub_High_Income_non$Gross.domestic.product.2012))
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
mergedData$RankingGroups = cut2(mergedData$Gross.domestic.product.2012, g=5 )
mergedData$RankingGroups = cut2(as.numeric(mergedData$Gross.domestic.product.2012), g=5 )
table(mergedData$RankingGroups)
table(mergedData$RankingGroups, mergedData$Income.Group)
gdp = read.csv("GDP_Data_Q3.csv",colClasses="character")
education = read.csv("educational_Data_Q3.csv",colClasses="character")
str(gdp)
str(education)
gdp$X
education$CountryCode
gdp = subset(gdp, gdp$X != "" | gdp$Gross.domestic.product.2012 != "")
gdp$X
gdp = subset(gdp, gdp$X != "" & gdp$Gross.domestic.product.2012 != "")
gdp$X
gdp$Gross.domestic.product.2012
gdp$X
gdp$Gross.domestic.product.2012
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=FALSE)
str(mergedData)
sum(is.na(mergedData$Gross.domestic.product.2012))
sum(is.na(mergedData$X))
mergedData <- mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012)) , ]
mergedData$Gross.domestic.product.2012
mergedData$Long.Name
str(mergedData)
mergedData$X.2
?order
gdp = read.csv("GDP_Data_Q3.csv",colClasses="character")
education = read.csv("educational_Data_Q3.csv",colClasses="character")
gdp = subset(gdp, gdp$X != "" & gdp$Gross.domestic.product.2012 != "")
mergedData = merge(gdp, education, by.x="X", by.y="CountryCode", all=FALSE)
mergedData <- mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012, decreasing=T)) , ]
mergedData$Gross.domestic.product.2012
mergedData <- mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012, decreasing=FALSE)) , ]
mergedData$Gross.domestic.product.2012
mergedData <- mergedData[order(as.numeric(mergedData$Gross.domestic.product.2012, decreasing=TRUE)) , ]
mergedData$Gross.domestic.product.2012
mergedData <- mergedData[order(as.numeric(-mergedData$Gross.domestic.product.2012)) , ]
mergedData <- mergedData[order(-as.numeric(mergedData$Gross.domestic.product.2012)) , ]
mergedData$Gross.domestic.product.2012
mergedData$Long.Name
mergedData$X.2
